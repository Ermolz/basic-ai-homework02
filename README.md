# Класифікація Iris: класичні та новітні методи (реалізація з нуля)

## 1. Мета завдання

Мета роботи — **реалізувати з нуля декілька класичних та новітніх методів класифікації**,  
а потім **порівняти їх роботу на одному й тому самому датасеті** (Iris).

За умовами завдання потрібно:

- взяти **задачу класифікації** з реального датасету (у нас — `Iris`);
- реалізувати **кілька різних підходів**:
  - класичні методи (метричні, ймовірнісні, логічні, логістична регресія),
  - новітні методи (метод опорних векторів, ансамблеві методи);
- **не використовувати готові класифікатори** з бібліотек (усе зроблено вручну: `fit/predict` реалізовані своїми руками);
- порівняти якість класифікації (accuracy) для кожного методу.

---

## 2. Використаний датасет

Використовується класичний датасет **Iris**:

- 4 ознаки:
  - довжина чашолистка (`sepal_length`),
  - ширина чашолистка (`sepal_width`),
  - довжина пелюстка (`petal_length`),
  - ширина пелюстка (`petal_width`);
- 3 класи (три види ірисів):
  - `0` — *setosa*,
  - `1` — *versicolor*,
  - `2` — *virginica*.

Дані зберігаються локально у файлі:

```text
iris.csv
````

Формат CSV (з заголовком):

```text
sepal_length,sepal_width,petal_length,petal_width,target
5.1,3.5,1.4,0.2,0
...
```

Файл читається функцією:

```python
X, y = load_iris_from_csv("iris.csv")
```

---

## 3. Структура та логіка коду

Основний файл (наприклад, `main.py`) містить:

1. **Допоміжні функції:**

   * `train_test_split_custom(X, y, test_size, random_state)`
     Ручний поділ на навчальну та тестову вибірки:

     * перемішує індекси об’єктів;
     * частину віддає в train, решту — в test.
   * `load_iris_from_csv(path)`
     Завантажує `iris.csv` з диску, розділяє на:

     * `X` — матриця ознак;
     * `y` — вектор класів.
   * `accuracy(y_true, y_pred)`
     Обчислює **точність класифікації** як частку правильно класифікованих об’єктів.
   * `StandardScalerManual`
     Ручна реалізація стандартизації ознак (mean=0, std=1).
     Використовується для методів, чутливих до масштабу: k-NN, логістична регресія, SVM.

2. **Класифікатори (методи класифікації), кожен у своєму класі:**

### 3.1. Класичні методи (розділ 2.1)

| № підпункту | Метод                                | Клас у коді                                         | Тип методу                            | Короткий опис                                                                                     |        |
| ----------: | ------------------------------------ | --------------------------------------------------- | ------------------------------------- | ------------------------------------------------------------------------------------------------- | ------ |
|       2.1.1 | Метричний метод k найближчих сусідів | `KNNClassifier`                                     | Класичний метричний метод             | Подання об’єктів як точок у просторі ознак; класифікація за більшістю серед k найближчих сусідів. |        |
|       2.1.2 | Наївний баєсівський класифікатор     | `GaussianNBManual`                                  | Класичний ймовірнісний метод          | Використовує формулу Баєса та гаусовий розподіл ознак; оцінює P(класу) та P(ознаки                | клас). |
|       2.1.3 | Дерево рішень                        | `DecisionTreeClassifierManual` + `DecisionTreeNode` | Логічний / графовий метод             | Будує дерево if–else з використанням індексу Джині; кожен лист відповідає класу.                  |        |
|       2.1.4 | Логістична регресія (softmax)        | `LogisticRegressionMulticlass`                      | Класичний лінійний ймовірнісний метод | Лінійна модель з softmax-виходом; навчається градієнтним спуском по крос-ентропійній втраті.      |        |

Коротко по кожному:

* **`KNNClassifier` (метричний метод)**
  Зберігає всі навчальні об’єкти.
  Для нового об’єкта:

  * рахує евклідові відстані до всіх `X_train`,
  * знаходить `k` найближчих,
  * обирає клас більшості (голосування сусідів).

* **`GaussianNBManual` (наївний Баєс)**
  На етапі `fit`:

  * для кожного класу обчислює середнє та дисперсію ознак,
  * рахує апріорні ймовірності класів.
    При передбаченні:
  * через гаусову формулу рахує лог-правдоподібність `log P(x | C)`,
  * додає `log P(C)`,
  * обирає клас з максимальним лог-апостеріором.

* **`DecisionTreeClassifierManual` + `DecisionTreeNode` (дерево рішень)**
  Будує дерево з розбиттями виду:

  * `feature_j <= threshold` → ліве піддерево,
  * інакше → праве.
    На кожному вузлі шукається найкращий поділ за **індексом Джині**.
    В листі дерева — клас, який переважає серед об’єктів у цьому листі.

* **`LogisticRegressionMulticlass` (логістична регресія)**
  Лінійна модель + softmax:

  * `scores = X @ W + b`,
  * `probs = softmax(scores)`.
    Навчання: градієнтний спуск по крос-ентропійній втраті + опційна L2-регуляризація.
    Дає на виході ймовірності класів та передбачає клас з максимальною ймовірністю.

---

### 3.2. Новітні методи (розділ 2.2)

| № підпункту | Метод                          | Клас у коді                    | Тип методу                 | Короткий опис                                                                                                     |
| ----------: | ------------------------------ | ------------------------------ | -------------------------- | ----------------------------------------------------------------------------------------------------------------- |
|       2.2.1 | Метод опорних векторів (SVM)   | `LinearSVMOneVsRest`           | Новітній метод, SVM        | Лінійний SVM у схемі one-vs-rest; максимізує margin, використовує hinge-втрату та L2-регуляризацію.               |
|       2.2.2 | Випадковий ліс (Random Forest) | `RandomForestClassifierManual` | Новітній ансамблевий метод | Ансамбль дерев рішень з бутстрап-зразками та випадковим підбором ознак; фінальне рішення — голосування більшості. |

Коротко:

* **`LinearSVMOneVsRest` (метод опорних векторів, SVM)**
  Для кожного класу навчається свій SVM:

  * позитивний клас = поточний клас,
  * негативний = всі інші.
    Використовується **hinge-втрата** та L2-регуляризація,
    навчання — через градієнтний спуск.
    Для нового об’єкта обчислюються score для кожного класу, вибирається клас з максимальним score.

* **`RandomForestClassifierManual` (випадковий ліс)**
  Будує **ансамбль дерев рішень** на базі `DecisionTreeClassifierManual`:

  * кожне дерево навчається на своєму бутстрап-зразку (випадкова вибірка з поверненням),
  * на кожному спліті дерево бачить лише підмножину ознак.
    При передбаченні всі дерева голосують, і обирається клас більшості.

---

## 4. Запуск експерименту

У блоці:

```python
if __name__ == "__main__":
    ...
```

відбувається:

1. Завантаження даних з `iris.csv`:

   ```python
   X, y = load_iris_from_csv("iris.csv")
   ```

2. Поділ на train/test:

   ```python
   X_train, X_test, y_train, y_test = train_test_split_custom(
       X, y, test_size=0.3, random_state=42
   )
   ```

3. Стандартизація ознак для чутливих методів:

   ```python
   scaler = StandardScalerManual()
   X_train_scaled = scaler.fit_transform(X_train)
   X_test_scaled = scaler.transform(X_test)
   ```

4. Оголошення всіх моделей у словнику `models`:

   ```python
   models = {
       "metric_kNN": KNNClassifier(k=5),
       "probabilistic_GaussianNB": GaussianNBManual(),
       "logical_DecisionTree": DecisionTreeClassifierManual(),
       "logistic_regression": LogisticRegressionMulticlass(...),
       "modern_SVM": LinearSVMOneVsRest(...),
       "modern_RandomForest": RandomForestClassifierManual(...)
   }
   ```

5. Цикл навчання та оцінки кожної моделі:

   ```python
   for name, model in models.items():
       print("=" * 80)
       print(f"Метод: {name}")

       if isinstance(model, (KNNClassifier, LogisticRegressionMulticlass, LinearSVMOneVsRest)):
           model.fit(X_train_scaled, y_train)
           y_pred = model.predict(X_test_scaled)
       else:
           model.fit(X_train, y_train)
           y_pred = model.predict(X_test)

       acc = accuracy(y_test, y_pred)
       print(f"Accuracy: {acc:.4f}")
   ```

На виході в консолі друкується точність (accuracy) для кожного методу.

---

## 5. Короткий підсумок

* Завдання: **порівняти різні методи класифікації** (класичні та новітні) на одному датасеті.
* Усі методи реалізовані **власноруч**, без використання вбудованих класифікаторів sklearn.
* Код організовано так, що кожен метод — це окремий клас з інтерфейсом `fit/predict`.
* Це дозволяє:

  * легко порівнювати методи;
  * чітко показати, як працює **кожен підхід всередині**;
  * прямо прив’язати код до теоретичних підпунктів 2.1 і 2.2 в звіті.

